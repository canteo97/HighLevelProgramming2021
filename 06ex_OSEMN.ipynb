{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named \"data_int.txt\". Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named \"data_float.txt\". Use the `cat` command to print the content of the file.\n",
    "+ load the txt file of the previous point and convert it to a csv file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " .1.\".\". . .2.\".\". . .3.\".\". . .4.\".\". . .5.\".\"\n",
      " . .6.\".\". . .7.\".\". . .8.\".\". . .9.\".\". .1.0.\".\"\n",
      " .1.1.\".\". .1.2.\".\". .1.3.\".\". .1.4.\".\". .1.5.\".\"\n",
      " .1.6.\".\". .1.7.\".\". .1.8.\".\". .1.9.\".\". .2.0.\".\"\n",
      " .2.1.\".\". .2.2.\".\". .2.3.\".\". .2.4.\".\". .2.5.\".\"\n"
     ]
    }
   ],
   "source": [
    "integ = [i for i in range(50)]\n",
    "with open('data_int.txt', 'w') as f:\n",
    "    f.write(str(integ)) #data need to be converted to string\n",
    "    \n",
    "#!type data_int.txt # type is the equivalent of cat command for windows\n",
    "\n",
    "matr = np.array([float(i) for i in range(1,26)]).reshape(5,5)\n",
    "with open('data_float.txt','w') as g:\n",
    "    g.write(str(matr))\n",
    "    \n",
    "#!type data_float.txt\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('data_float.txt','r') as h:\n",
    "    m = h.readlines()\n",
    "#print(m)\n",
    "m = [m[i].replace(\"\\n\",\"\") for i in range(len(m))]\n",
    "m = [m[i].replace(\"[\",\"\") for i in range(len(m))]\n",
    "m = [m[i].replace(\"]\",\"\") for i in range(len(m))]\n",
    "n = []*25\n",
    "\n",
    "#print(m)\n",
    "with open('data_float.csv','w', newline = \"\\n\") as i:\n",
    "    csv.writer(i, delimiter = \".\").writerows(m)\n",
    "    \n",
    "!type data_float.csv \n",
    "#data is not represented correctly due to the delimiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Load the file *user_data.json*, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",ID,JobTitle,EmailAddress,FirstNameLastName,CreditCard,CreditCardType\n",
      "1,2,Investment  Advisor,Clint_Thorpe5003@bulaffy.com,Clint Thorpe,7083-8766-0251-2345,American Express\n",
      "11,12,Retail Trainee,Phillip_Carpenter9505@famism.biz,Phillip Carpenter,3657-0088-0820-5247,American Express\n",
      "27,28,Project Manager,Russel_Graves1378@extex.org,Russel Graves,6718-4818-8011-6024,American Express\n",
      "38,39,Stockbroker,Leanne_Newton1268@typill.biz,Leanne Newton,5438-0816-4166-4847,American Express\n",
      "56,57,Budget Analyst,Tony_Giles1960@iatim.tech,Tony Giles,8130-3425-7573-7745,American Express\n",
      "61,62,CNC Operator,Owen_Allcott5125@bauros.biz,Owen Allcott,4156-0107-7210-2630,American Express\n",
      "67,68,Project Manager,Liam_Lynn3280@kideod.biz,Liam Lynn,7152-3247-6053-2233,American Express\n",
      "73,74,Dentist,Regina_Woodcock5820@yahoo.com,Regina Woodcock,0208-1753-3870-8002,American Express\n",
      "80,81,HR Specialist,Carter_Wallace9614@atink.com,Carter Wallace,4256-7201-6717-4322,American Express\n",
      "91,92,Staffing Consultant,Maia_Stark2797@jiman.org,Maia Stark,3851-1403-1734-6321,American Express\n",
      "96,97,Stockbroker,Ciara_Lomax982@bauros.biz,Ciara Lomax,3702-3440-2472-5424,American Express\n",
      "115,116,Staffing Consultant,Isabel_Ellwood1475@fuliss.net,Isabel Ellwood,3738-0882-0066-6683,American Express\n",
      "147,148,CNC Operator,Abdul_Townend2202@infotech44.tech,Abdul Townend,4224-1226-3557-3448,American Express\n",
      "149,150,Fabricator,Caleb_Poulton1735@atink.com,Caleb Poulton,8203-6875-5225-0341,American Express\n",
      "150,151,Restaurant Manager,Ronald_Lewis6777@deavo.com,Ronald Lewis,7212-0155-5014-8471,American Express\n",
      "153,154,Bellman,Faith_Seymour3829@twace.org,Faith Seymour,4170-5186-6887-6558,American Express\n",
      "168,169,Assistant Buyer,Anthony_Hancock9083@qater.org,Anthony Hancock,0832-3357-6010-6550,American Express\n",
      "175,176,Healthcare Specialist,Isabella_Willson5478@nanoff.biz,Isabella Willson,5177-4868-4623-0384,American Express\n",
      "181,182,Pharmacist,Stephanie_Darcy3298@bauros.biz,Stephanie Darcy,0264-4020-5106-5576,American Express\n",
      "198,199,Investment  Advisor,Ryan_Kennedy5565@corti.com,Ryan Kennedy,3166-6287-6242-7207,American Express\n"
     ]
    }
   ],
   "source": [
    "#instruction used to load the file\n",
    "#!wget https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json -P data/ --no-check-certificate\n",
    "import json\n",
    "data = json.load(open('data/user_data.json'))\n",
    "#print(data)\n",
    "\n",
    "user = pd.read_json(\"data/user_data.json\")\n",
    "#print(user)\n",
    "\n",
    "filtered_user = user[user['CreditCardType'] == 'American Express']\n",
    "#print(filtered_user)\n",
    "\n",
    "filtered_user.to_csv(\"filtered_user.csv\") \n",
    "!type filtered_user.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = \"https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv?dl=1\"\n",
    "#added ?dl=1 to the url in order to force the download\n",
    "mush = pd.read_csv(url)\n",
    "#print(mush)\n",
    "\n",
    "#print(list(mush.columns))\n",
    "for i in range(len(list(mush.columns))):\n",
    "    mushg = mush.groupby(list(mush.columns)[i]).mean()\n",
    "    #print(\"Average value of \", list(mush.columns)[i], \" is \", mushg)\n",
    "\n",
    "mush.to_json(\"mushrooms.json\") #used pandas to move the dataframe to json file\n",
    "#!type mushrooms.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Get the binary file named *credit_card.dat* from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['110111110110110100111000100000110101110110110111110011100000110011110111110111110101100000110010110010110111110001', '110011110010110101110111100000111000110010110100110111100000110011110011110101110100100000110010110010110110110110', '110010110111110010110010100000110000110000110000110001100000110100110000110001110001100000110110110110110101110010', '110000110110110110110001100000110011110000110110110011100000110011110111110100110010100000110011110001110101110000', '110000110100110011110010100000110001110110110000111000100000110001110100110110110010100000110100110111110100110010', '110101111000110010110111100000110010110000110010110111100000111000110111111000110101100000110111110011110000110011', '110101110111110111110100100000111000110101110010111000100000110010110000111000110111100000110001110001110001110111', '111000110001110100110000100000110001110010110001110000100000110110110011110101110010100000110010111000110100110101', '110101110111110110110100100000110001110001110011110011100000110111110011110000110001100000110111110001110000110000', '110110110100110101110110100000110001110111110011110111100000110100110001110010110110100000110110110111110010110110', '110001110010110010111000100000111000110110110011110001100000110111110011111000110010100000110000110000110000110000', '110111110000110101110001100000110000110001110110110000100000110101110011110111110100100000110011110001110110110110', '110000110110110001111000100000110011110101111000110111100000110001110110110011110000100000110110110011110111110110', '110001110101110100110101100000110101110100110101110100100000110111110100110100110100100000110101110110110011110110', '110110110111110011110101100000110011110001110001110110100000110011110010110000110010100000110110111000110011110100', '110111110010111000110111100000110101110000110001110001100000110001110101110100110111100000111000110100110001110011', '110111110000110011110011100000110010110110110000110111100000110011110011110010111000100000110100110010110000110000', '110010110101110110111000100000110101110010110100110100100000110001111000110111110100100000110101110000110010110100', '110001110110111000110100100000110010110010110101110011100000110111110101110111110000100000110111110001110001111000', '110000110110110111110010100000110010110101110111110110100000110000110101110111110101100000110110110110110011110001', '110110110011110011110010100000111000110011110101110011100000111000110111111000110111100000110001110011110100110000', '110001111000110001110011100000110011110011110110110001100000110001110001110111110101100000110100110010110001110001', '110010110100110111110111100000110110110100110101110000100000111000111000110100110000100000110010110011110110111000', '110101110101110001110010100000110011110101110000110101100000110010110101110110110011100000110001110011110010110110', '110011110000111000110011100000110111111000111000110010100000110000110110110010110001100000110000110000110010110101', '110100110101110010110001100000110101110001110100111000100000111000110000110100110101100000110000110011110011110100', '110111110101110110110011100000110011110110110101110100100000111000110111110001110011100000110101110111111000110111', '111000110011110010110100100000110010110110110110110100100000110000110100110111110110100000110101110101110110110001', '110000110101110110110101100000110010110101110000110100100000110111110001110110111000100000110011110101110001110000', '110101110001110000110111100000110101110101110000110111100000110001110111110110110111100000110000110111110011111000', '110010110100110110110010100000110001111000110010110001100000110010110100110100111000100000110001110100110100110011', '110010110111111000111000100000110000110110110011111000100000110110111000110110110001100000110110110101110101110100', '110101111000110101110001100000110101111000110111110011100000110101110100110111110100100000110000110101110100110111', '110000110110110111110000100000110001110000110000110100100000110100110000110001110011100000110010110110110101110101', '110101111000110111110100100000110101110101110000110110100000110011110000110100111000100000110000111000110000110110', '110010111000110000110101100000110101110100110000110001100000111000110100110110110010100000110001110010110110110000', '110101110000111000110011100000111000110100110000110110100000110110110011110001110000100000110001111000110110110010', '110001110000110111110110100000110001110100110100110101100000110011110000110001110011100000110010110010110110110110', '111000110100110100110000100000110100111000110000110100100000110100111000110100110100100000110101110010110111110111', '110100110111110101111000100000110110110001110100110001100000110000110110111000110110100000110001110011111000110111', '110111110101111000110110100000110000110110110111110101100000110000110011110001110101100000110010110101110110111000', '110010110101110100110100100000110001110010110101111000100000110111110100110011110010100000110101110001110110110101', '110011110100110111110100100000110101110000110010110011100000110100110100110011110100100000110101110110110010110110', '110001110100110001110000100000110000110010110111110000100000110000110100110011110100100000110101110000111000110110', '110111110011110001110101100000110100110100110100110110100000110001110001110000110100100000110100110010110001110101', '110000110010110010110100100000110111110111110100110010100000111000110011110000110000100000110000110010110110110110', '110000110001110111110000100000110010110111110000110000100000110011110001110100110101100000110000110110110100110000', '110010110000110000110110100000110010110100110011110111100000111000110000110101110100100000110001110110110000110000', '111000110001110100110010100000110100110000110101110101100000110001110111110111110110100000110000110000110010110110', '110011110000110010110110100000110111110011111000110000100000110001110010110100110001100000110001110000111000110100', '1010', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "#!wget https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat --no-check-certificate\n",
    "#!type credit_card.dat\n",
    "\n",
    "with open('credit_card.dat', 'rb') as file:\n",
    "    file_content = str(file.read())\n",
    "    file_content = file_content.replace(\"b'\",\"\")\n",
    "    card_size = 16\n",
    "    block = 4\n",
    "    number = 6\n",
    "    #first_number = file_content[0 : 0+number]\n",
    "    #print(first_number)\n",
    "    credit_cards = file_content.split(\"\\\\n\")\n",
    "    #print(file_content)\n",
    "    #print(credit_cards)\n",
    "    #print(len(credit_cards))\n",
    "    \n",
    "    for i in range(len(credit_cards)):\n",
    "        credit_cards[i] = credit_cards[i][0:114] #removing the last 4 bits from each row\n",
    "        for j in range(len(0,credit_cards[i]),6):\n",
    "            \n",
    "    print(credit_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Optional**: load the remote file:\n",
    "\n",
    "- https://www.dropbox.com/s/aamg1apjhclecka/regression_generated.csv\n",
    "\n",
    "with Pandas and create a scatter plot with all possible combinations of the following features:\n",
    "    \n",
    "  + features_1\n",
    "  + features_2\n",
    "  + features_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
